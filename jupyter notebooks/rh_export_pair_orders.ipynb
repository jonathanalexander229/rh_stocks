{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will use the robin_stocks.robinhood.export functions which write all orders to a csv file, then we will parse them and attempt to pair the opening and closing orders.  This is a WORK IN PROGRESS.  the cells for AAPL orders appear to be working.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: robin_stocks in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (3.0.6)\n",
      "Requirement already satisfied: pandas in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: ipykernel in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (6.29.3)\n",
      "Requirement already satisfied: requests in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from robin_stocks) (2.31.0)\n",
      "Requirement already satisfied: pyotp in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from robin_stocks) (2.9.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from robin_stocks) (1.0.1)\n",
      "Requirement already satisfied: cryptography in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from robin_stocks) (42.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: appnope in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (8.18.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (8.6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (24.0)\n",
      "Requirement already satisfied: psutil in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipykernel) (5.14.2)\n",
      "Requirement already satisfied: decorator in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.10.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (7.0.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from cryptography->robin_stocks) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from requests->robin_stocks) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from requests->robin_stocks) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from requests->robin_stocks) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from requests->robin_stocks) (2024.2.2)\n",
      "Requirement already satisfied: pycparser in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography->robin_stocks) (2.21)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.18.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/clutchcoder/working/venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install robin_stocks pandas numpy ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log on to the robinhood API endpoint, and create the output directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robin_stocks.robinhood as r\n",
    "import pandas as pd\n",
    "import os  \n",
    "# Prompt for email address\n",
    "email = input(\"Please enter your Robinhood email address: \")\n",
    "\n",
    "login = r.login(email)\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = '../output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get all the options orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Additional pages.\n",
      "Loading page 2 ...\n",
      "Loading page 3 ...\n",
      "Loading page 4 ...\n",
      "Loading page 5 ...\n",
      "Loading page 6 ...\n",
      "Loading page 7 ...\n"
     ]
    }
   ],
   "source": [
    "# # Get all option orders\n",
    "r.export_completed_option_orders('/', file_name='../output/options_output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This groups spread order by order_created_at and then calculates total cost based on debit and credit direction.  Spreads orders show up multiple time (number of legs) with the total price and quantity listed on each order, so we group them and only sum them up once per opening and closing spread order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total option cost: $-3247.00\n",
      "878\n",
      "1625.0\n",
      "Total opening strategy quantity: 1008.0\n",
      "Total closing strategy quantity: 618.0\n",
      "Opening strategy rows: 544\n",
      "Closing strategy rows: 335\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your spreadsheet\n",
    "df = pd.read_csv('../output/options_output.csv')\n",
    "\n",
    "# Convert 'order_created_at' to datetime\n",
    "df['order_created_at'] = pd.to_datetime(df['order_created_at'])\n",
    "df['order_created_at'] = df['order_created_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Filter for the year 2024\n",
    "#df = df[df['order_created_at'].str.startswith('2024')]\n",
    "\n",
    "# Select only the columns we want\n",
    "df = df[['order_created_at', 'chain_symbol', 'expiration_date', \n",
    "         'strike_price', 'option_type', 'direction', 'order_quantity', \n",
    "         'order_type', 'opening_strategy', 'closing_strategy', 'price', 'order_quantity']]\n",
    "\n",
    "# Group by 'order_created_at' and aggregate\n",
    "aggregated_df = df.groupby('order_created_at').agg({\n",
    "    'chain_symbol': 'first',\n",
    "    'expiration_date': 'first',\n",
    "    'strike_price': lambda x: list(sorted(x, key=abs, reverse=True)),  # Create a list of strike price\n",
    "    'option_type': 'first',\n",
    "    'direction': 'first',\n",
    "    'opening_strategy': 'first',\n",
    "    'closing_strategy': 'first',\n",
    "    'price': 'first',\n",
    "    'order_quantity': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Sort the DataFrame\n",
    "aggregated_df = aggregated_df.sort_values(by=['chain_symbol', 'expiration_date'])\n",
    "\n",
    "# Calculate cost\n",
    "aggregated_df['cost'] = aggregated_df['price'] * aggregated_df['order_quantity'] * 100\n",
    "\n",
    "# Adjust the cost based on the direction\n",
    "aggregated_df['cost'] = aggregated_df.apply(\n",
    "    lambda x: -x['cost'] if x['direction'] == 'debit' else x['cost'],\n",
    "    axis=1\n",
    ")      \n",
    "\n",
    "total_option_cost = aggregated_df['cost'].sum()\n",
    "print(f\"Total option cost: ${total_option_cost:.2f}\")\n",
    "print(aggregated_df['order_created_at'].count())\n",
    "print(aggregated_df['order_quantity'].sum())\n",
    "\n",
    "# Save the results\n",
    "aggregated_df.to_csv('../output/options_orders_parsed.csv', index=False)\n",
    "\n",
    "# Count rows where 'opening_strategy' is not None\n",
    "total_opening_strategy_count = aggregated_df['opening_strategy'].notna().sum()\n",
    "total_closing_strategy_count = aggregated_df['closing_strategy'].notna().sum()\n",
    "\n",
    "\n",
    "# # Count rows where 'closing_strategy' contains 'spread' or 'iron'\n",
    "# spread_closing_count = df['closing_strategy'].str.contains('spread|iron', case=False, na=False).sum()\n",
    "\n",
    "# # Count rows where 'opening_strategy' contains 'spread' or 'iron'\n",
    "# spread_opening_count = df['opening_strategy'].str.contains('spread|iron', case=False, na=False).sum()\n",
    "\n",
    "# # Count rows where 'closing_strategy' contains 'spread' or 'iron'\n",
    "# non_spread_closing_count = total_closing_strategy_count - spread_closing_count\n",
    "\n",
    "# # Count rows where 'opening_strategy' contains 'spread' or 'iron'\n",
    "# non_spread_opening_count = total_opening_strategy_count - spread_opening_count\n",
    "# Calculate total order quantity for opening_strategy\n",
    "total_opening_quantity = aggregated_df['order_quantity'][aggregated_df['opening_strategy'].notna()].sum()\n",
    "print(f\"Total opening strategy quantity: {total_opening_quantity}\")\n",
    "\n",
    "# Calculate total order quantity for closing_strategy\n",
    "total_closing_quantity = aggregated_df['order_quantity'][aggregated_df['closing_strategy'].notna()].sum()\n",
    "print(f\"Total closing strategy quantity: {total_closing_quantity}\")\n",
    "\n",
    "\n",
    "#Print the counts\n",
    "print(f\"Opening strategy rows: {total_opening_strategy_count}\")\n",
    "print(f\"Closing strategy rows: {total_closing_strategy_count}\")\n",
    "# print(f\"Opening strategy rows with 'spread' or 'iron': {spread_opening_count}\")\n",
    "# print(f\"Closing strategy rows with 'spread' or 'iron': {spread_closing_count}\")\n",
    "# print(f\"Opening strategy rows not with 'spread' or 'iron': {non_spread_opening_count}\")\n",
    "# print(f\"Closing strategy rows not with 'spread' or 'iron': {non_spread_closing_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is no longer working after I've changed the strike column to be a list\n",
    "\n",
    "# AAPL Spread Order Analysis\n",
    "\n",
    "This cell analyzes AAPL spread orders by:\n",
    "\n",
    "1. Filtering for AAPL spread/iron condor orders\n",
    "2. Pairing opening orders with corresponding closing orders\n",
    "3. Handling partial closings and multiple closing orders per opening order\n",
    "4. Calculating total opened and closed quantities\n",
    "5. Identifying unpaired (still open) orders\n",
    "\n",
    "The analysis provides:\n",
    "- Count of paired and unpaired orders\n",
    "- Detailed view of first few paired orders (open and close details)\n",
    "- List of unpaired (open) orders\n",
    "- Summary of total opened, closed, and remaining open quantities\n",
    "\n",
    "This helps in understanding the current state of AAPL spread positions, including fully closed, partially closed, and still open trades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (11,), (2,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     21\u001b[0m remaining_quantity \u001b[38;5;241m=\u001b[39m order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_quantity\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     22\u001b[0m matching_closes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m potential_closes \u001b[38;5;241m=\u001b[39m aapl_spreads[\n\u001b[1;32m     25\u001b[0m     (aapl_spreads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclosing_strategy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     26\u001b[0m     (aapl_spreads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpiration_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpiration_date\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m---> 27\u001b[0m     (\u001b[43maapl_spreads\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstrike_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstrike_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     28\u001b[0m     (aapl_spreads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption_type\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     29\u001b[0m ]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, close_order \u001b[38;5;129;01min\u001b[39;00m potential_closes\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining_quantity \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/working/venv/lib/python3.9/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/working/venv/lib/python3.9/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/working/venv/lib/python3.9/site-packages/pandas/core/series.py:6110\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6107\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6108\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6110\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/working/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:321\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# TODO: make this treatment consistent across ops and classes.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m#  We are not catching all listlikes here (e.g. frozenset, tuple)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m#  The ambiguous case is object-dtype.  See GH#27803\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lvalues) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rvalues):\n\u001b[0;32m--> 321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    326\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    328\u001b[0m ):\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(lvalues, rvalues)\n",
      "\u001b[0;31mValueError\u001b[0m: ('Lengths must match to compare', (11,), (2,))"
     ]
    }
   ],
   "source": [
    "# Assuming we're using the aggregated_df from the previous cell\n",
    "\n",
    "# Filter for AAPL spread orders\n",
    "aapl_spreads = aggregated_df[\n",
    "    (aggregated_df['chain_symbol'] == 'AAPL') & \n",
    "    (aggregated_df['opening_strategy'].str.contains('spread|iron', case=False, na=False) | \n",
    "     aggregated_df['closing_strategy'].str.contains('spread|iron', case=False, na=False))\n",
    "]\n",
    "\n",
    "# Sort by expiration date and strike price\n",
    "# aapl_spreads = aapl_spreads.sort_values(['expiration_date', 'strike_price'])\n",
    "\n",
    "# Initialize lists to store paired and unpaired orders\n",
    "paired_orders = []\n",
    "unpaired_opens = []\n",
    "\n",
    "# Iterate through the orders\n",
    "for _, order in aapl_spreads.iterrows():\n",
    "    if pd.notna(order['opening_strategy']):\n",
    "        # This is an opening order\n",
    "        remaining_quantity = order['order_quantity']\n",
    "        matching_closes = []\n",
    "\n",
    "        potential_closes = aapl_spreads[\n",
    "            (aapl_spreads['closing_strategy'].notna()) &\n",
    "            (aapl_spreads['expiration_date'] == order['expiration_date']) &\n",
    "            (aapl_spreads['strike_price'] == order['strike_price']) &\n",
    "            (aapl_spreads['option_type'] == order['option_type'])\n",
    "        ]\n",
    "\n",
    "        for _, close_order in potential_closes.iterrows():\n",
    "            if remaining_quantity > 0:\n",
    "                matched_quantity = min(remaining_quantity, close_order['order_quantity'])\n",
    "                matching_closes.append((close_order, matched_quantity))\n",
    "                remaining_quantity -= matched_quantity\n",
    "\n",
    "        if matching_closes:\n",
    "            paired_orders.append((order, matching_closes))\n",
    "            for close_order, _ in matching_closes:\n",
    "                aapl_spreads = aapl_spreads[aapl_spreads.index != close_order.name]\n",
    "        else:\n",
    "            unpaired_opens.append(order)\n",
    "\n",
    "    aapl_spreads = aapl_spreads[aapl_spreads.index != order.name]\n",
    "\n",
    "# Print results\n",
    "print(f\"Paired orders: {len(paired_orders)}\")\n",
    "print(f\"Unpaired opening orders: {len(unpaired_opens)}\")\n",
    "\n",
    "# Display first few paired orders\n",
    "for i, (open_order, close_orders) in enumerate(paired_orders[:5]):\n",
    "    print(f\"\\nPair {i+1}:\")\n",
    "    print(f\"Open: {open_order['order_created_at']} - {open_order['strike_price']} - {open_order['opening_strategy']} - Quantity: {open_order['order_quantity']}\")\n",
    "    total_closed = sum(close_order[1] for close_order in close_orders)\n",
    "    print(f\"Closed: {total_closed} out of {open_order['order_quantity']}\")\n",
    "    for j, (close_order, matched_quantity) in enumerate(close_orders):\n",
    "        print(f\"  Close {j+1}: {close_order['order_created_at']} - {close_order['strike_price']} - {close_order['closing_strategy']} - Matched Quantity: {matched_quantity}\")\n",
    "\n",
    "# Display unpaired opening orders\n",
    "print(\"\\nUnpaired opening orders:\")\n",
    "for i, order in enumerate(unpaired_opens[:5]):\n",
    "    print(f\"{i+1}: {order['order_created_at']} - Exp: {order['expiration_date']} - {order['strike_price']} - {order['opening_strategy']} - Quantity: {order['order_quantity']}\")\n",
    "\n",
    "# Calculate total opened and closed quantities\n",
    "total_opened = sum(order['order_quantity'] for order, _ in paired_orders) + sum(order['order_quantity'] for order in unpaired_opens)\n",
    "total_closed = sum(sum(close_order[1] for close_order in close_orders) for _, close_orders in paired_orders)\n",
    "\n",
    "print(f\"\\nTotal opened quantity: {total_opened}\")\n",
    "print(f\"Total closed quantity: {total_closed}\")\n",
    "print(f\"Remaining open quantity: {total_opened - total_closed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAPL Spread Order Analysis\n",
    "\n",
    "This cell analyzes AAPL spread orders by:\n",
    "\n",
    "1. Filtering for AAPL spread/iron condor orders\n",
    "2. Pairing opening orders with corresponding closing orders\n",
    "3. Handling partial closings and multiple closing orders per opening order\n",
    "4. Calculating total opened and closed quantities\n",
    "5. Identifying unpaired (still open) orders\n",
    "\n",
    "The analysis provides:\n",
    "- Count of paired and unpaired orders\n",
    "- Detailed view of first few paired orders (open and close details)\n",
    "- List of unpaired (open) orders\n",
    "- Summary of total opened, closed, and remaining open quantities\n",
    "\n",
    "For unpaired opening orders, it searches for potential closing orders of individual legs by matching:\n",
    "- Expiration date\n",
    "- Any matching strike price\n",
    "- AAPL as the underlying\n",
    "\n",
    "This helps in understanding the current state of AAPL spread positions, including fully closed, partially closed, and still open trades, as well as identifying potential leg-by-leg closures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total quantity of unpaired opening orders: 0\n",
      "Number of unpaired opening orders: 0\n"
     ]
    }
   ],
   "source": [
    "# Assuming we're using the aggregated_df and aapl_spreads from the previous cell\n",
    "\n",
    "# Convert strike_price to float when creating aggregated_df\n",
    "aggregated_df = df.groupby('order_created_at').agg({\n",
    "    'chain_symbol': 'first',\n",
    "    'expiration_date': 'first',\n",
    "    'strike_price': lambda x: [float(s) for s in sorted(x, key=abs, reverse=True)],\n",
    "    'option_type': 'first',\n",
    "    'direction': 'first',\n",
    "    'order_quantity': 'first',\n",
    "    'order_type': 'first',\n",
    "    'opening_strategy': 'first',\n",
    "    'closing_strategy': 'first',\n",
    "    'price': 'first',\n",
    "    'order_quantity': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Function to extract strike prices from the strike_price string\n",
    "def extract_strikes(strike_string):\n",
    "    return [float(s.strip('+-')) for s in strike_string.split('/')]\n",
    "\n",
    "# Process unpaired opening orders\n",
    "for i, open_order in enumerate(unpaired_opens):\n",
    "    print(f\"\\nAnalyzing unpaired order {i+1}:\")\n",
    "    print(f\"Open: {open_order['order_created_at']} - Exp: {open_order['expiration_date']} - {open_order['strike_price']} - {open_order['opening_strategy']} - Quantity: {open_order['order_quantity']}\")\n",
    "    \n",
    "    strikes = extract_strikes(open_order['strike_price'])\n",
    "    \n",
    "    potential_closes = aggregated_df[\n",
    "        (aggregated_df['closing_strategy'].notna()) &\n",
    "        (aggregated_df['expiration_date'] == open_order['expiration_date']) &\n",
    "        (aggregated_df['chain_symbol'] == 'AAPL') &\n",
    "        (aggregated_df['strike_price'].apply(lambda x: any(s in strikes for s in x)))\n",
    "    ]\n",
    "    \n",
    "    if not potential_closes.empty:\n",
    "        print(\"Potential closing orders for individual legs:\")\n",
    "        for _, close in potential_closes.iterrows():\n",
    "            print(f\"  Close: {close['order_created_at']} - Exp: {close['expiration_date']} - {close['strike_price']} - {close['closing_strategy']} - Quantity: {close['order_quantity']}\")\n",
    "    else:\n",
    "        print(\"No potential closing orders found for individual legs.\")\n",
    "\n",
    "# Calculate and print summary\n",
    "total_unpaired_quantity = sum(order['order_quantity'] for order in unpaired_opens)\n",
    "print(f\"\\nTotal quantity of unpaired opening orders: {total_unpaired_quantity}\")\n",
    "print(f\"Number of unpaired opening orders: {len(unpaired_opens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analysis for AAPL ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (878,), (2,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     19\u001b[0m unpaired_opens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, order \u001b[38;5;129;01min\u001b[39;00m symbol_spreads\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     21\u001b[0m     closing_order \u001b[38;5;241m=\u001b[39m aggregated_df[\n\u001b[1;32m     22\u001b[0m         (aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchain_symbol\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m symbol) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     23\u001b[0m         (aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclosing_strategy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspread|iron\u001b[39m\u001b[38;5;124m'\u001b[39m, case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     24\u001b[0m         (aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpiration_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpiration_date\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m---> 25\u001b[0m         (\u001b[43maggregated_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstrike_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstrike_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     26\u001b[0m     ]\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closing_order\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     28\u001b[0m         unpaired_opens\u001b[38;5;241m.\u001b[39mappend(order)\n",
      "File \u001b[0;32m~/working/venv/lib/python3.9/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/working/venv/lib/python3.9/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/working/venv/lib/python3.9/site-packages/pandas/core/series.py:6110\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6107\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6108\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6110\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/working/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:321\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# TODO: make this treatment consistent across ops and classes.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m#  We are not catching all listlikes here (e.g. frozenset, tuple)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m#  The ambiguous case is object-dtype.  See GH#27803\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lvalues) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rvalues):\n\u001b[0;32m--> 321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    326\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    328\u001b[0m ):\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(lvalues, rvalues)\n",
      "\u001b[0;31mValueError\u001b[0m: ('Lengths must match to compare', (878,), (2,))"
     ]
    }
   ],
   "source": [
    "# Get all unique chain symbols\n",
    "unique_symbols = aggregated_df['chain_symbol'].unique()\n",
    "\n",
    "# Function to extract strike prices from the strike_price string\n",
    "def extract_strikes(strike_string):\n",
    "    return [float(s.strip('+-')) for s in strike_string.split('/')]\n",
    "\n",
    "# Analyze each symbol\n",
    "for symbol in unique_symbols:\n",
    "    print(f\"\\n--- Analysis for {symbol} ---\")\n",
    "    \n",
    "    # Filter for the current symbol's spread orders\n",
    "    symbol_spreads = aggregated_df[\n",
    "        (aggregated_df['chain_symbol'] == symbol) & \n",
    "        (aggregated_df['opening_strategy'].str.contains('spread|iron', case=False, na=False))\n",
    "    ]\n",
    "    \n",
    "    # Find unpaired opening orders\n",
    "    unpaired_opens = []\n",
    "    for _, order in symbol_spreads.iterrows():\n",
    "        closing_order = aggregated_df[\n",
    "            (aggregated_df['chain_symbol'] == symbol) &\n",
    "            (aggregated_df['closing_strategy'].str.contains('spread|iron', case=False, na=False)) &\n",
    "            (aggregated_df['expiration_date'] == order['expiration_date']) &\n",
    "            (aggregated_df['strike_price'] == order['strike_price'])\n",
    "        ]\n",
    "        if closing_order.empty:\n",
    "            unpaired_opens.append(order)\n",
    "\n",
    "    # Process unpaired opening orders\n",
    "    for i, open_order in enumerate(unpaired_opens):\n",
    "        print(f\"\\nAnalyzing unpaired order {i+1}:\")\n",
    "        print(f\"Open: {open_order['order_created_at']} - Exp: {open_order['expiration_date']} - {open_order['strike_price']} - {open_order['opening_strategy']} - Quantity: {open_order['order_quantity']}\")\n",
    "        \n",
    "        strikes = set(open_order['strike_price'])\n",
    "        \n",
    "        potential_closes = aggregated_df[\n",
    "            (aggregated_df['closing_strategy'].notna()) &\n",
    "            (aggregated_df['expiration_date'] == open_order['expiration_date']) &\n",
    "            (aggregated_df['chain_symbol'] == symbol) &\n",
    "            (aggregated_df['strike_price'].apply(lambda x: any(s in strikes for s in x)))\n",
    "        ]\n",
    "        \n",
    "        if not potential_closes.empty:\n",
    "            print(\"Potential closing orders for individual legs:\")\n",
    "            for _, close in potential_closes.iterrows():\n",
    "                print(f\"  Close: {close['order_created_at']} - Exp: {close['expiration_date']} - {close['strike_price']} - {close['closing_strategy']} - Quantity: {close['order_quantity']}\")\n",
    "        else:\n",
    "            print(\"No potential closing orders found for individual legs.\")\n",
    "\n",
    "    # Calculate and print summary for this symbol\n",
    "    total_unpaired_quantity = sum(order['order_quantity'] for order in unpaired_opens)\n",
    "    print(f\"\\nTotal quantity of unpaired opening orders for {symbol}: {total_unpaired_quantity}\")\n",
    "    print(f\"Number of unpaired opening orders for {symbol}: {len(unpaired_opens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aggregated_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m  \u001b[38;5;66;03m# Use json to parse the string representation of lists/dictionaries\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m unique_symbols \u001b[38;5;241m=\u001b[39m \u001b[43maggregated_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchain_symbol\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      6\u001b[0m total_option_event_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Initialize total cash amount\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create a list to store event data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aggregated_df' is not defined"
     ]
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "import pandas as pd\n",
    "import json  # Use json to parse the string representation of lists/dictionaries\n",
    "\n",
    "unique_symbols = aggregated_df['chain_symbol'].unique()\n",
    "total_option_event_cost = 0  # Initialize total cash amount\n",
    "\n",
    "# Create a list to store event data\n",
    "event_data = []\n",
    "\n",
    "for symbol in unique_symbols:\n",
    "    events = r.get_events(symbol)  # Fetch events for the symbol\n",
    "    for event in events:\n",
    "        # Ignore rows with total_cash_amount = 0\n",
    "        if float(event['total_cash_amount']) == 0 :\n",
    "            continue\n",
    "        \n",
    "        # Append event details to the list\n",
    "        event_data.append({\n",
    "            'created_at': event['created_at'],\n",
    "            'chain_symbol': symbol,\n",
    "            'direction': event['direction'],\n",
    "            'quantity': event['quantity'],\n",
    "            'total_cash_amount': event['total_cash_amount'],\n",
    "            'state': event['state'],\n",
    "            'underlying_price': event['underlying_price']\n",
    "        })\n",
    "        if event['direction'] == 'credit':\n",
    "            total_option_event_cost += float(event['total_cash_amount'])  # Add for exercise\n",
    "        elif event['direction'] == 'debit':\n",
    "            total_option_event_cost -= float(event['total_cash_amount'])  # Subtract for assignment\n",
    "\n",
    "# Create a DataFrame from the event data\n",
    "events_df = pd.DataFrame(event_data)\n",
    "\n",
    "# Save the events DataFrame to a new CSV file\n",
    "events_df.to_csv('../output/option_events.csv', index=True)\n",
    "\n",
    "\n",
    "# Print the total cash amount\n",
    "print(f\"Total cash amount: {total_option_event_cost}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8919.601299630365\n"
     ]
    }
   ],
   "source": [
    "total =  total_option_cost + total_stock_cost + total_crypto_cost + abs(total_option_event_cost)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
